{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a076f437",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481b8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d5c31",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c44685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users.\n",
    "# Average computation time without optimization : 10s/user --> 6100s --> less than 2 hours\n",
    "# Full: 27,000,000 ratings and 1,100,000 tag applications applied to 58,000 movies by 280,000 users.\n",
    "# Average computation time without optimization : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e093eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\"\n",
    "DATASET_TYPE = \"small\"\n",
    "TRAIN_SIZE = 0.8\n",
    "MINIMUM_SEEN_MOVIES = 1\n",
    "MINIMUM_SEEN_USERS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f29d4c",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1b9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, dataset_type=\"small\"):\n",
    "\tif dataset_type == \"small\":\n",
    "\t\tmovies = pd.read_csv(path + \"ml-latest-small/movies.csv\")\n",
    "\t\tratings = pd.read_csv(path + \"ml-latest-small/ratings.csv\")\n",
    "\telif dataset_type == \"full\":\n",
    "\t\tmovies = pd.read_csv(path + \"ml-latest/movies.csv\")\n",
    "\t\tratings = pd.read_csv(path + \"ml-latest/ratings.csv\")\n",
    "\treturn movies, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae37329",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies, ratings = load_data(PATH, DATASET_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eda4a1",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675978bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete films seen only by a certain number of users\n",
    "def get_id_delete_solo_films(data, threshold,nom_colonne) :\n",
    "    '''\n",
    "    data -> movies ou ratings ( dataframe qui contient une colonne movieId )\n",
    "    '''\n",
    "    list_key_values = np.array(list(Counter(data[nom_colonne].values).items()))\n",
    "    key,values = list_key_values[:,0],list_key_values[:,1]\n",
    "    id_delete =  np.where(values < threshold)[0]\n",
    "    return key[id_delete]\n",
    "\n",
    "def delete_solo_films(data,id_delete,nom_colonne) :\n",
    "    '''\n",
    "    data -> movies ou ratings ( dataframe qui contient une colonne movieId )\n",
    "    '''\n",
    "    array_movieId = data[nom_colonne].values\n",
    "    ind = [i for i in range(len(array_movieId)) if array_movieId[i] not in id_delete ]\n",
    "    return data.iloc[ind]\n",
    "\n",
    "\n",
    "## Building ratings and movies dataframe which both contains the same movieId\n",
    "def clear_dataset(movies, ratings):\n",
    "\n",
    "\tid_delete = get_id_delete_solo_films(ratings, MINIMUM_SEEN_MOVIES,'movieId')\n",
    "\tratings = delete_solo_films(ratings,id_delete,'movieId')\n",
    "\tmovies = delete_solo_films(movies,id_delete,'movieId')\n",
    "\tid_delete = get_id_delete_solo_films(ratings, MINIMUM_SEEN_USERS,'userId')\n",
    "\tratings = delete_solo_films(ratings,id_delete,'userId')\n",
    "\t\n",
    "\tlist_movieId = list(set(movies[\"movieId\"].values).intersection(set(ratings[\"movieId\"].values)))\n",
    "\tmovies_old = movies['movieId'].values\n",
    "\tl = []\n",
    "\tfor i in range(len(movies_old)):\n",
    "\t\tif movies_old[i] in list_movieId:\n",
    "\t\t\tl.append(i)\n",
    "\tmovies = movies.iloc[l,:]\n",
    "\n",
    "\ta = sorted(list(list_movieId))\n",
    "\tb = range(len(a))\n",
    "\td = dict(zip(a,b))\n",
    "\tmovies = movies.replace({'movieId' : d})\n",
    "\n",
    "\ta = sorted(list(list_movieId))\n",
    "\tb = range(len(a))\n",
    "\td = dict(zip(a,b))\n",
    "\tratings = ratings.replace({'movieId' : d})\n",
    "    \n",
    "\tratings.index = range(len(ratings))\n",
    "\tmovies.index = range(len(movies))\n",
    "\n",
    "\treturn movies, ratings\t\n",
    "\t\n",
    "## Building one hot encoded genres in movies dataframe\n",
    "def one_hot_encode_genres(movies):\n",
    "\ttmp = []\n",
    "\tfor elt in movies[\"genres\"]:\n",
    "\t\ttmp.append(elt.split(\"|\"))\n",
    "\tmovies[\"genres\"] = tmp\n",
    "\tmlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\tmovies = movies.join(\n",
    "\t\t\t\tpd.DataFrame.sparse.from_spmatrix(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmlb.fit_transform(movies.pop('genres')),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tindex=movies.index,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tcolumns=mlb.classes_))\n",
    "\treturn movies\n",
    "\n",
    "## Cleaning ratings datagrame\n",
    "def preprocess_ratings(ratings):\n",
    "\tratings = ratings.drop(columns=[\"timestamp\"])\n",
    "\tratings['userId'] = ratings['userId'].to_numpy() - 1 # car pas de user 0\n",
    "\treturn ratings\n",
    "\n",
    "## Split for computing metrics on test later\n",
    "def split_set(userId, train_size, ratings):\n",
    "\trating_user = ratings[ratings[\"userId\"] == userId]\n",
    "\ttrain_rating_user, test_rating_user = rating_user.to_numpy()[:int(train_size*len(rating_user))], rating_user.to_numpy()[int(train_size*len(rating_user)):]\n",
    "\treturn train_rating_user, test_rating_user\n",
    "\n",
    "## Get informations on users watched/unwatched movies...\n",
    "def get_infos_user(userId):\n",
    "\twatched_user = set(ratings[ratings[\"userId\"] == userId][\"movieId\"])\n",
    "\twatched_all = set(ratings['movieId'])\n",
    "\tunwatched_user = list(watched_all.difference(watched_user))\n",
    "\treturn watched_user, watched_all, unwatched_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8a7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies, ratings = clear_dataset(movies, ratings)\n",
    "movies = one_hot_encode_genres(movies)\n",
    "ratings = preprocess_ratings(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0081e",
   "metadata": {},
   "source": [
    "# Building matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025984d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a sparse matrix which contains the triple (u_k, m_i, r_ki)\n",
    "# def build_sparse_matrix_triples(ratings):\n",
    "# \tratings_sparse = scipy.sparse.csr_matrix(ratings.values)\n",
    "# \treturn ratings_sparse\n",
    "\n",
    "## Building a matrix M = (n_movies, n_movies) which contains the number of users who'se seen m_i and m_j\n",
    "def build_M_matrix(ratings, train_size):\n",
    "\tdata_dict = dict()\n",
    "\ttrain_rating_user_list = []\n",
    "\ttest_rating_user_list = []\n",
    "\tfor userId in tqdm(set(ratings[\"userId\"])):\n",
    "\t\ttrain_rating_user, test_rating_user = split_set(userId, train_size, ratings)\n",
    "\t\ttrain_rating_user_list.append(np.array(train_rating_user))\n",
    "\t\ttest_rating_user_list.append(np.array(test_rating_user))\n",
    "\t\titerator = it.combinations(train_rating_user[:,1], 2)\n",
    "\t\tfor x, y in iterator:\n",
    "\t\t\tdata_dict[(x,y)] = data_dict.get((x,y), 0.) + 1.\n",
    "\t\t\tdata_dict[(y,x)] = data_dict.get((y,x), 0.) + 1.\n",
    "\t\titerator = it.combinations(test_rating_user[:,1], 2)\n",
    "\t\tfor x, y in iterator:\n",
    "\t\t\t# We need to ignore the test movies\n",
    "\t\t\tdata_dict[(x,y)] = 0\n",
    "\t\t\tdata_dict[(y,x)] = 0\n",
    "\tkeys = np.array(list(data_dict.keys())).astype(int)\n",
    "\tvalues = np.array(list(data_dict.values())).astype(float)\n",
    "\tM_coo = scipy.sparse.coo_matrix((values, (keys[:,0], keys[:,1])))\n",
    "\tM_csr = M_coo.tocsr()\n",
    "\tM_norm = M_csr\n",
    "\treturn M_norm, train_rating_user_list, test_rating_user_list\n",
    "\n",
    "## Computing probabilites of genres P_ig\n",
    "def build_P_ig(movies):\n",
    "\tsum_ = movies[[i for i in movies.columns if i != \"movieId\" and i != \"title\"]].to_numpy().sum(axis=0).astype(int)\n",
    "\tP_ig = sum_ / sum(sum_)\n",
    "\treturn P_ig.reshape(-1, 1)\n",
    "\n",
    "## Initialisation of R_uk before iterative algorithm\n",
    "def init_R_uk(movies):\n",
    "\tn_genres = len(movies.columns) - 2\n",
    "\tn_movies = len(movies)\n",
    "\tr = 1/(n_movies*n_genres)\n",
    "\tR_uk = np.full((n_movies, n_genres), r)\n",
    "\treturn R_uk\n",
    "\n",
    "## Computing F_ig for each user\n",
    "def build_F_ig(R_uk, P_ig):\n",
    "\tF_ig = np.sum(R_uk, axis=1).reshape(-1,1) @ P_ig.reshape(1,-1)\n",
    "\treturn F_ig\n",
    "\n",
    "## Matrix user X movie\n",
    "def build_ratings_matrix(ratings):\n",
    "\tvalues = ratings[\"rating\"]\n",
    "\trows = ratings[\"userId\"]\n",
    "\tcols = ratings[\"movieId\"]\n",
    "\tM_coo = scipy.sparse.coo_matrix((values, (rows, cols)))\n",
    "\tM_csr = M_coo.tocsr()\n",
    "\treturn M_csr\n",
    "\n",
    "## Build I_uk for each user\n",
    "def build_I_uk(tmp_M, id_user, P_ig):\n",
    "# \tprint(tmp_M[id_user,:].T.shape)\n",
    "\tI_uk = tmp_M[id_user,:].T @ P_ig.reshape(1,-1)\n",
    "\tI_uk = I_uk / I_uk.sum(axis=0).T\n",
    "\treturn I_uk\n",
    "\n",
    "## Init the matrix needed before running the iterative algorithm\n",
    "def init(movies, ratings, train_size):\n",
    "\tprint(\"Init R_uk...\")\n",
    "\tR_uk = init_R_uk(movies)\n",
    "\tprint(R_uk.shape)\n",
    "\tprint(\"Building P_ig...\")\n",
    "\ttmp_M = build_ratings_matrix(ratings)\n",
    "\tP_ig = build_P_ig(movies)\n",
    "\tprint(P_ig.shape)\n",
    "\tprint(\"Building M_csr...\")\n",
    "\tM_csr, train_rating_user_list, test_rating_user_list = build_M_matrix(ratings, train_size)\n",
    "\tprint(M_csr.shape)\n",
    "\treturn R_uk, tmp_M, P_ig, M_csr, np.array(train_rating_user_list, dtype=object), np.array(test_rating_user_list, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec458e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init R_uk...\n",
      "(9724, 20)\n",
      "Building P_ig...\n",
      "(20, 1)\n",
      "Building M_csr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [00:33<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 9724)\n"
     ]
    }
   ],
   "source": [
    "R_uk, tmp_M, P_ig, M_csr, train_rating_user_list, test_rating_user_list = init(movies, ratings, TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6051cda",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ac2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute TR_ki for a specific user\n",
    "def compute_TR_ki(id_user, R_uk, tmp_M, P_ig, M_csr, d, alpha, iter_max):\n",
    "\tI_uk = build_I_uk(tmp_M, id_user, P_ig)\n",
    "\tfor _ in range(iter_max):\n",
    "\t\tF_ig = build_F_ig(R_uk, P_ig)\n",
    "\t\tR_uk = d * alpha * M_csr @ R_uk + d * (1-alpha) * M_csr @ F_ig + (1-d) * I_uk\n",
    "\n",
    "\t\t# This part is useful if you want to normalize + break if converge\n",
    "\t\t# R_uk = (R_uk / R_uk.sum(axis=1)).T # Normalization isn't working\n",
    "\t\t#     print(np.abs(np.sum(R_uk - R_uk_old)))\n",
    "\t\t#     if np.abs(np.sum(R_uk - R_uk_old)) < eps :\n",
    "\t\t#         print(i)\n",
    "\t\t#         break\n",
    "\t\t# R_uk_old = R_uk.copy()\n",
    "\t\n",
    "\tTR_ki = np.array(R_uk @ P_ig) # It returns a np.mat object which can't be reduced to dimension 1\n",
    "\treturn TR_ki.reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "## Compute TR_ki for all users\n",
    "def iterative_TR_ki(n_user, R_uk, tmp_M, P_ig, M_csr, d=0.15, alpha=0.1, iter_max=5):\n",
    "\tprint(\"Computing TR_ki for all users...\")\n",
    "\tTR_ki_all_user = []\n",
    "\n",
    "\t# pool_obj = multiprocessing.Pool(processes=4)\n",
    "\t# prod_x = partial(compute_TR_ki, R_uk=R_uk, tmp_M=tmp_M, P_ig=P_ig, M_csr=M_csr, d=d, alpha=alpha, iter_max=iter_max)\n",
    "\t# pool_obj.map(prod_x, range(n_user))\n",
    "\n",
    "\tfor id_user in tqdm(range(n_user)):\n",
    "\t\tTR_ki_all_user.append(compute_TR_ki(id_user, R_uk, tmp_M, P_ig, M_csr, d, alpha, iter_max))\n",
    "\n",
    "\treturn np.array(TR_ki_all_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e820f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TR_ki for all users...\n"
     ]
    }
   ],
   "source": [
    "# n_user = len(np.unique(ratings[\"userId\"]))\n",
    "n_user = 3 ## Use when testing\n",
    "\n",
    "TR_ki_all_user = iterative_TR_ki(n_user, R_uk, tmp_M, P_ig, M_csr, d=0.15, alpha=0.1, iter_max=15)\n",
    "# Parallel(n_jobs=2)(delayed(iterative_TR_ki)(n_user, R_uk, tmp_M, P_ig, M_csr, d=0.15, alpha=0.1, iter_max=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a8aae",
   "metadata": {},
   "source": [
    "## Running some test for a test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns the recommandation for the users\n",
    "def sort_by_best_movie(TR_ki_all_user):\n",
    "\tsorted_movies_all_user = np.zeros_like(TR_ki_all_user)\n",
    "\tfor i in range(len(TR_ki_all_user)):\n",
    "\t\tsorted_movies_all_user[i,:] = np.argsort(TR_ki_all_user[i,:])[::-1]\n",
    "\treturn sorted_movies_all_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5718f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = 1\n",
    "\n",
    "print(\"TR_ki_all_user shape:\", TR_ki_all_user.shape)\n",
    "print(\"test_rating_user_list shape:\", test_rating_user_list.shape)\n",
    "print(\"TR_ki for test user :\\n\", TR_ki_all_user[test_user_id, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00396e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_movies_all_user = sort_by_best_movie(TR_ki_all_user)\n",
    "print(\"sorted_movies_all_user shape:\", sorted_movies_all_user.shape)\n",
    "print(\"Sorted best movies recommandation for test user :\\n\", sorted_movies_all_user[test_user_id,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967928da",
   "metadata": {},
   "source": [
    "## Running some test for the DOA metrics before computing it on whole user list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43786ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes DOA score for a specific user\n",
    "def compute_doa_score(TR_ki, test_rating_user, unwatched_user):\n",
    "\tscore = 0\n",
    "\tfor m_i in test_rating_user:\n",
    "\t\tfor m_j in unwatched_user:\n",
    "\t\t\tif TR_ki[int(m_i)] > TR_ki[int(m_j)]:\n",
    "\t\t\t\tscore += 1\n",
    "\treturn score / (len(test_rating_user) * len(unwatched_user))\n",
    "\n",
    "## Computes DOA for the whole user list\n",
    "def compute_all_doa(TR_ki_all_user, test_rating_user_list):\n",
    "\tscore = 0\n",
    "\tn_user = TR_ki_all_user.shape[0]\n",
    "\tfor user_id in range(n_user):\n",
    "\t\ttmp = test_rating_user_list[user_id]\n",
    "\t\ttest_films = tmp[:,1]\n",
    "\t\tTR_ki = TR_ki_all_user[user_id]\n",
    "\t\t_, _, unwatched_films = get_infos_user(user_id)\n",
    "\t\tscore += compute_doa_score(TR_ki, test_films, unwatched_films)\n",
    "\treturn score / n_user\n",
    "\n",
    "def test_doa_user(n_user, n_film_test):\n",
    "\tfor test_user_id in range(n_user):\n",
    "\t\tprint(\"---------- Testing user number\", test_user_id, \"----------\")\n",
    "\t\ttest = test_rating_user_list[test_user_id]\n",
    "\t\ttest_films = test[:,1]\n",
    "\t\tTR_ki = TR_ki_all_user[test_user_id]\n",
    "\t\t_, _, unwatched_films = get_infos_user(test_user_id)\n",
    "\t\tprint(\"Some movies from test set:\")\n",
    "\t\tprint(test_films[:n_film_test])\n",
    "\t\tprint(\"Some movies from unwatched set:\")\n",
    "\t\tprint(unwatched_films[:n_film_test])\n",
    "\t\tprint(\"Some score for test set (movies watched by user):\")\n",
    "\t\tfor i in test_films[:n_film_test]:\n",
    "\t\t\tprint(TR_ki[int(i)])\n",
    "\t\tprint(\"Some score for unwatched movies:\")\n",
    "\t\tfor i in unwatched_films[:n_film_test]:\n",
    "\t\t\tprint(TR_ki[int(i)])\n",
    "\t\tprint(\"Total DOA score for this user :\", compute_doa_score(TR_ki, test_films, unwatched_films))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doa_user(n_user=1, n_film_test=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d5093",
   "metadata": {},
   "source": [
    "## Computing final DOA metric for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DOA for all users :\", compute_all_doa(TR_ki_all_user, test_rating_user_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92bb73",
   "metadata": {},
   "source": [
    "## Building a dataset to do an experiment campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_experimental_dataset(movies, TR_ki_all_user, train_rating_user_list, test_rating_user_list, n_user, n_film_test):\n",
    "\tdataset = []\n",
    "\tdict_id_title = dict(zip(list(movies['movieId']),list(movies['title'])))\n",
    "\tfor userId in range(n_user) :\n",
    "\t\ttrain_rating_user = train_rating_user_list[0][:,1].astype(int)\n",
    "\t\ttest_rating_user = test_rating_user_list[0][:,1].astype(int)\n",
    "\t\t_, _, unwatched_user = get_infos_user(userId)\n",
    "\t\tunwatched_user = np.append(test_rating_user, unwatched_user)\n",
    "\n",
    "\t\tind_sort =  np.argsort(TR_ki_all_user[userId,:])[::-1]\n",
    "\n",
    "\t\twatched_user_final = []\n",
    "\t\tunwatched_user_final = []\n",
    "\n",
    "\t\tfor ind in ind_sort :\n",
    "\n",
    "\t\t\tif ind in train_rating_user:\n",
    "\t\t\t\twatched_user_final.append(ind)\n",
    "\t\t\telse : #ind in unwatched_user_final\n",
    "\t\t\t\tunwatched_user_final.append(ind)\n",
    "\n",
    "\t\twatched_user_best = watched_user_final[:n_film_test]\n",
    "\t\tunwatched_user_best = unwatched_user_final[:n_film_test]\n",
    "\t\tunwatched_user_rand = np.random.choice(np.array(unwatched_user_final[n_film_test+1:]), size=n_film_test)\n",
    "\n",
    "\t\twatched_user_best_dict = { str(movieId) : dict_id_title[movieId] for movieId in watched_user_best } \n",
    "\t\tunwatched_user_best_dict = { str(movieId) : dict_id_title[movieId] for movieId in unwatched_user_best } \n",
    "\t\tunwatched_user_rand_dict = { str(movieId) : dict_id_title[movieId] for movieId in unwatched_user_rand }\n",
    "\n",
    "\t\tdataset.append((watched_user_best_dict,unwatched_user_best_dict,unwatched_user_rand_dict))\n",
    "\n",
    "\treturn np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2525da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_experimental_dataset(movies, TR_ki_all_user, train_rating_user_list, test_rating_user_list, n_user, n_film_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d337118",
   "metadata": {},
   "source": [
    "## Testing our experiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = 0\n",
    "dataset[userId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db19137",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user_experiment = 10\n",
    "print(dataset[:n_user_experiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79de2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dataset[:n_user_experiment]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcc17e",
   "metadata": {},
   "source": [
    "## Explication & Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uk -> user k \n",
    "# ig -> movies i, genre g \n",
    "# R_uk -> movie,genre pour user uk\n",
    "# P_ig -> désigne la probabilité avec laquelle l'item i appartient au genre g\n",
    "# M -> matrice correlation\n",
    "# F -> \n",
    "# I_uk -> \n",
    "# r_ki -> \n",
    "\n",
    "#R -> n_user X n_movies X n_genres\n",
    "#I -> n_user X n_movies X n_genres\n",
    "\n",
    "#M -> n_movies X n_movies\n",
    "#F_ig -> n_movies X n_genres\n",
    "#I_uk -> n_movies X n_genres\n",
    "\n",
    "# Split train test sur les users????????\n",
    "# Entrainement sur le train \n",
    "# Test a la fin comparaison NDCG entre tri du ranking et notes de l'utilisateur \n",
    "\n",
    "# Split train test sur les ratings par users (on ignore les ratings test pour le train)\n",
    "# Entrainement sur le train (il reste le meme, on a juste caché des notes)\n",
    "# Test a la fin comparaison NDCG entre tri du ranking (donné par l'algo grace au train) et notes de l'utilisateur (qu'on a garder en test)\n",
    "# Test avec le DOA entre les films (qu'on a cache) et les films unwatched ?\n",
    "\n",
    "# On prend pour un utilisateur sa liste de film + ses notes\n",
    "# On montre cette liste a des nouveaux utilisateurs puis on leur demande parmis les films que notre algo sort quel est celui qui devrait etre recommandé\n",
    "# On compare les resultats avec notre ranking reel apres train\n",
    "# Test de student "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
